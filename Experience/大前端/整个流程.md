# 简单流程

## 查看云服务器信息

查看服务器信息

```
lsb_release -a
```



查看 linux 内核版本

```
unman -a
```



df 命令可以检查系统磁盘空间的占用情况

```
df 或 df -Th
```



查看文件目录

```
cd / 来到根目录下
ls -la 查看所有文件
```

home 相当于我们的个人目录，我们存放的东西可以放到这个 home 目录下面去

etc 里存放软件的配置文件

sys 是系统目录

usr 放置系统的可执行文件

var 存放一些日志文件，里面还会存放 www 目录



查看运行着的进程

```
top
```



## 安装 docker

https://github.com/docker/docker-install#usage

```
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

两句命令安装 docker 
```



## 安装 docker-compose

https://docs.docker.com/compose/install/#install-compose-on-linux-systems

使用如下命令安装：

```
sudo curl -L "https://github.com/docker/compose/releases/download/1.28.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
```

再使用如下命令给其一个执行权限：

```
sudo chmod +x /usr/local/bin/docker-compose
```

然后就可以使用 docker-compose 命令了，使用 docker-compose -v 查看版本



## 安装 mongo

在 docker hub 上搜索 mongo

https://hub.docker.com/_/mongo

使用 `docker pull mongo` 去拉取 mongo 最新的镜像

也可以使用 `docker pull mongo:4` 安装 4 版本

> 这时可能安装不了，是因为 docker 没有 `daemon.json` 文件
>
> 在 linux 上 `cd /etc/docker/daemon.json`，没有的话就创建一个 daemon.json 文件



在 daemon.json 文件中加入这行代码（docker 的中国镜像源加速）：

```
{
 "registry-mirrors": ["https://registry.docker-cn.com"]
}
```

然后执行

```
service docker restart
```

重启 docker

然后使用如下命令拉取 mongo

```
docker pull mongo:4
```



下载完后，可以通过如下命令查看本地下载了哪些镜像

```
docker images
```



接下来通过一句命令运行 mongo

https://hub.docker.com/_/mongo

```
docker run --name some-mongo -d mongo:tag
```

例如

```
docker run --name some-mongo -d -p 10050:27017 mongo:tag
```

如上即是从服务器上的 10050 端口映射到容器上的 27017 端口

The MongoDB server in the image listens on the standard MongoDB port, `27017`



使用如下命令来查看目前运行的 docker 服务

```
docker ps
```

 会看到

```
ports: 0.0.0.0:10050->27017/tcp  names: some-mongo
```



然后需要验证和测试，在这之前需要放行防火墙端口

可以直接关闭防火墙：

```
Ubuntu: service ufw stop
Centos: service firewalld stop
```

但是一般是将 10050 端口添加到放行的端口中去：

```
firewall-cmd --zone=public --add-port=10050/tcp --permanent
```

然后会显示 success，即成功添加，然后重新加载

```
firewall-cmd --reload
```

查看防火墙的运行状态：

```
firewall-cmd --state
```

使用 `Robo 3T` 可以远程连接 mongo 服务



## Yarn 和 Nvm

安装 nvm：

https://github.com/nvm-sh/nvm#installing-and-updating

直接在 linux 中 install

```
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.2/install.sh | bash
```

使用 `nvm list` 可以查看安装好的 node 版本列表，然后可以通过 `nvm use v10.15.3` 来切换到其他版本

使用 `nvm --help` 可以查看有哪些指令

然后再将 nvm 的环境变量添加到我们的系统环境变量里面去

> 可以直接使用 nvm 下载 node ！！！！
>
> 参考网址：https://juejin.cn/post/6844903827582238733
>
> ```nginx
> 1，安装10.15.3版本node
> [root@izbp1b498epn4trb75oykez ~]# nvm i 10.15.3
> 
> 2，查看本地安装的node和正在使用的版本
> [root@izbp1b498epn4trb75oykez ~]# nvm ls
> ```



安装 yarn：

```
curl -o- -L https://yarnpkg.com/install.sh | bash
```

参考网址：https://www.jackpu.com/yarn-facebook-kai-yuan-de-bao-guan-li-gong-ju/



通过如下命令更改 yarn 的镜像源

```
yarn config set registry 'https://registy.npm.taobao.org/'
```

通过 `yarn config get registry` 来查看当前镜像源

> yarn 安装完需要会提示需要 node 环境才能使用 yarn，此时需要用 nvm 安装 node，然后删除刚才安装的 yarn，再重新安装 yarn！！

通过 `yarn help` 来查看 yarn 有哪些指令



使用 yarn 全局安装 vue cli：

```
yarn global add @vue/cli
```





# Docker

## docker 入门

<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-03-03 下午3.58.31.png" alt="截屏2021-03-03 下午3.58.31" style="zoom:25%;" />

操作系统是指 linux macOS 等，在操作系统上去安装 docker 容器



docker的主要特性：

- 文件、资源、网络隔离
- 变更管理（类似 git 一样的版本仓库），日志记录
- 写时复制`（最重要！！）`(docker 采用写时复制的方式去创建根文件系统，虚拟机是首先切一部分系统资源，然后依据把镜像解压出来再安装。而写时复制是直接根据 docker 镜像去创建共有文件系统，让部署变得非常的快速)



docker 安装：参考网址https://www.toimc.com/docker%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/



启动 docker

```
systemctl start docker
```

查看 docker 状态

```
systemctl status docker
```



示例：

```
docker run hello-world
```

会提示本地没有该镜像，接着会从远程去拉取

```
Unable to find image 'hello-world:latest' locally

latest: Pulling from library/hello-world

Status: Downloaded newer image for hello-world:latest

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.
```



查看 docker 中运行的容器或镜像

```
docker ps

docker ps -a // -a 代表了所有的镜像，此时我们就可以看到有 hello-world 这个镜像
```



删除已经停止的容器

```
docker rm （后面接容器名称或容器id）
```

如果这个容器正在运行中，那么就不可以去删除它，那么就要先使用 `docker stop（后面接容器名称或容器id）` 去停止这个容器



docker 拉取 mysql：

前往 docker hub 搜索 mysql

使用命令

```
docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag
```

改为自己的名字和密码（-d 代表的是在后台去运行）（不加 tag 的话就代表是拉取最新的镜像 mysql:latest）

```
docker run --name rise-mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql
```

然后使用 `docker ps` 命令就可以查看已经在运行的 mysql



查看该日志（-f 是持续打印的意思）

```
docker logs -f rise-mysql
```



那么我们把容器里面的 mysql 通过`端口号`映射出来就可以使用了

删除原先的，再重新拉取一个

```
docker run --name rise-mysql -e MYSQL_ROOT_PASSWORD=123456 -p 28001:3306 -d mysql
```

28001 代表的是这台服务器上的端口，3306 代表的是容器内部的端口，也就是这个服务的端口

执行上述命令后立即返回一个哈希值，表明已经在运行

这就是所谓的 `写时复制`，它直接跳过了刚才的那个 pull 的环节，因为这个镜像已经变成了我们 local 的了，那么使用这条命令就可以直接去运行

那么就可以通过 28001 去连接 mysql

使用 docker 可以跑起很多种所需要的测试环境



## docker-compose

docker 可以帮我们把容器和应用打包成一个镜像，那么这个镜像就可以在任何有 docker 服务或者 docker daemon.json 的情况下运行起来

这样就不用担心环境的问题，担心各种依赖的版本问题



但是我们的容器中有很多的 App，不可能每个都去 run 和 start，那么这个时候就需要 docker-compose，可以用一条命令去运行镜像、管理镜像和查看镜像状态



A `docker-compose.yml` looks like this:

```yaml
version: "3.9"  # optional since v1.27.0 // 版本
services:	# 要运行的服务
  web: # 一个 web 服务
    build: .
    ports: # 使用了哪些端口
      - "5000:5000"
    volumes: # 挂载了哪些磁盘，和宿主机有哪些文件上的共享
      - .:/code
      - logvolume01:/var/log
    links: # 与哪个容器进行了相连
      - redis
  redis: # 一个 redis 服务
    image: redis # 使用的镜像
volumes:
  logvolume01: {}
```



示例：

首先

```
cd /home/
```

创建文件（也可以先在本地写好文件再传到远程服务器上去）

```
vi docker-compose.yml
```



写内容到文件中

```yaml
version: '3'
services:
  mysql1:
    image: mysql
    environment:
    - MYSQL_ROOT_PASSWORD=123456
    ports:
    - 28002:3306
  mysql2:
    image: mysql
    environment:
    - MYSQL_ROOT_PASSWORD=123456
    ports:
    - 28003:3306
```

-e 代表 environment 环境变量

将容器的 3306 端口映射到宿主机上的 28002 和 28003 上



接下来运行命令

```
docker-compose up -d
```

就会帮我们创建文件中那两个 mysql 了

使用 docker ps 命令就可以查看到它们的状态了



docker-compose 也有 run 和 start 命令

停止所有服务

```
docker-compose stop
```

删除所有容器

```
docker-compose rm
```



> 对于已经创建的容器，就不能再用 docker run 的命令去拉取了，因为它已经创建了，此时要用 docker start （后面接容器名称或容器id）！！！
>
> 同理，对于 docker-compose，就是 `docker-compose start` 和 `docker-compose stop` 命令来停止所有容器



## docker 仓库

docker hub

还有私有仓库 Harbor



使用终端登录 docker hub

```
docker login
```

然后输入用户名和密码即可



接下来我们可以推送镜像到 docker hub 上

例如我们可以推送刚才的 mysql 镜像

```
docker commit （docker 容器的id） （用户名/给镜像取的名字:tag）
```

例如

```
docker commit 91a6f285415d aboutcroon/rise-mysql:1.0
```

然后查看镜像

```
docker images
```

就可以看到刚才的镜像出现

```
REPOSITORY              TAG       IMAGE ID       CREATED         SIZE
aboutcroon/rise-mysql   1.0       487c2ba85b61   5 seconds ago   546MB
```



然后推送到远程的 docker hub 上去

```
docker push aboutcroon/rise-mysql:1.0
```

可以看到，推送的过程中，会有很多 mounted，如下

```
7c77abddd300: Mounted from library/mysql 
```

因为 docker 是一个文件系统，有一些已存在于 mysql 服务器上的文件系统，就不再进行推送，这样也节约的传输的时间

但是网络问题很可能会推送失败，所以很多中国的用户会创建自己的 docker 私仓，这样推送和拉取的速度都会比较快

上传完成后我们就可以使用 `docker pull` 去拉取了



# Node

- node 是免费的开源的跨平台应用

- 同时也是服务器上的 js 运行环境，方便 js 运行在服务器上面，以前 html css js 只是运行在浏览器上，有了 node 后它们就可以运行在服务器上了，这样我们就可以写接口去调用服务器上的资源

- node 核心是基于 chrome v8 引擎，有两个很重要的特性：`事件驱动`和`非阻塞I/O`



node.js 会带一个 npm 的包管理工具

不同的项目可能依赖的 node 版本不一样，这时候就可以通过 nvm 去管理 node 版本

使用 `nvm use （node版本）` 可以去进行 node 的版本切换



## 发布自己的 npm 包

创建一个文件夹

```
mkdir rise-module

cd rise-module
```

然后初始化一个包

```
npm init
```

然后在这个文件夹下会形成一个 `package.json` 文件



查看配置

```
npm config list
```

这里我们可以看到我们的仓库是"https://registry.npmjs.org/"

```
metrics-registry = "https://registry.npmjs.org/"
```

防止有时我们替换镜像源时，仓库变成 taobao 的仓库了

类似于 docker 有 docker hub 的仓库，npm 也有 npmjs 的仓库



使用如下命令添加本地用户，接着输入用户名和密码，邮箱

```
npm adduser
```

使用如下命令查看当前登录的是哪个用户

```
npm whoami
```

然后在文件夹下写一个简单的 index.js 文件

```js
function consol (params) {
  console.log(params)
}

module.exports = consol
```

接着发布（这些操作都是在这个 npm init 之后的文件夹下）

```
npm publish
```



# 版本控制 Git



# 搭建 Gitlab

gitlab 和 jenkens 进行了很好的集成

可以使用 docker，docker-compose 快速创建



进入 gitlab 官网，选择 docker 的方式进行安装

https://docs.gitlab.com/omnibus/docker/



一句 run 命令来搭建

https://docs.gitlab.com/omnibus/docker/#install-gitlab-using-docker-engine

```
sudo docker run --detach \
  --hostname gitlab.example.com \
  --publish 443:443 --publish 80:80 --publish 22:22 \
  --name gitlab \
  --restart always \
  --volume $GITLAB_HOME/config:/etc/gitlab \
  --volume $GITLAB_HOME/logs:/var/log/gitlab \
  --volume $GITLAB_HOME/data:/var/opt/gitlab \
  gitlab/gitlab-ee:latest
```

--hostname 是域名或者 ip

443 端口是走 https 的协议，80 端口是默认服务访问的端口，22 端口是克隆仓库要走的一个默认的端口（22 是默认的 ssh 端口，别人会对这个端口进行一些攻击，需要修改成其他的）。我们也可以自定义的将它们设置成我们想要的端口，冒号前面的端口代表着宿主机上的端口

--name 是指定镜像的名称

--restart 是指 docker 服务重启的时候 gitlab 的服务也自动的重启

--volume 是将 gitlab 的数据映射到宿主机上来



运行如下命令

```
sudo docker run --detach \
  --hostname 116.62.24.181 \
  --publish 13800:80 --publish 13822:22 \
  --name gitlab_test \
  --restart always \
  gitlab/gitlab-ee:latest
```

放行相应的端口

```
firewall-cmd --add-port=13800/tcp --permanent
firewall-cmd --reload
```

查看日志

```
docker logs -f gitlab_test
```



## install gitlab using docker-compose

使用 docker-compose 来搭建，可以通过 docker-compose.yml 文件来更好的管理接口

网址：https://docs.gitlab.com/omnibus/docker/#install-gitlab-using-docker-compose

在 home 目录下创建 docker-compose 文件夹，在这个文件夹下创建 docker-compose.yml 文件

```yaml
web:
  image: 'gitlab/gitlab-ee:latest'
  restart: always
  hostname: 'gitlab.example.com'
  environment:
    GITLAB_OMNIBUS_CONFIG: |
      external_url 'https://gitlab.example.com'
      # Add any other gitlab.rb configuration here, each on its own line
  ports:
    - '80:80'
    - '443:443'
    - '22:22'
  volumes:
    - '$GITLAB_HOME/config:/etc/gitlab'
    - '$GITLAB_HOME/logs:/var/log/gitlab'
    - '$GITLAB_HOME/data:/var/opt/gitlab'
```

ports 可以设置端口，volumes 可以设置在宿主机上的存储位置，environment 可以设置外部的地址

通过这种文档的形式我们就可以很方便的去管理 gitlab 的镜像



可以通过 github 上的开源 yml 文件来直接设置

网址：https://github.com/sameersbn/docker-gitlab



原版

```yaml
version: '2.3'

services:
  redis:
    restart: always
    image: redis:5.0.9
    command:
    - --loglevel warning
    volumes:
    - redis-data:/var/lib/redis:Z

  postgresql:
    restart: always
    image: sameersbn/postgresql:12-20200524
    volumes:
    - postgresql-data:/var/lib/postgresql:Z
    environment:
    - DB_USER=gitlab
    - DB_PASS=password
    - DB_NAME=gitlabhq_production
    - DB_EXTENSION=pg_trgm,btree_gist

  gitlab:
    restart: always
    image: sameersbn/gitlab:13.9.4
    depends_on:
    - redis
    - postgresql
    ports:
    - "10080:80"
    - "10022:22"
    volumes:
    - gitlab-data:/home/git/data:Z
    healthcheck:
      test: ["CMD", "/usr/local/sbin/healthcheck"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 5m
    environment:
    - DEBUG=false

    - DB_ADAPTER=postgresql
    - DB_HOST=postgresql
    - DB_PORT=5432
    - DB_USER=gitlab
    - DB_PASS=password
    - DB_NAME=gitlabhq_production

    - REDIS_HOST=redis
    - REDIS_PORT=6379

    - TZ=Asia/Kolkata
    - GITLAB_TIMEZONE=Kolkata

    - GITLAB_HTTPS=false
    - SSL_SELF_SIGNED=false

    - GITLAB_HOST=localhost
    - GITLAB_PORT=10080
    - GITLAB_SSH_PORT=10022
    - GITLAB_RELATIVE_URL_ROOT=
    - GITLAB_SECRETS_DB_KEY_BASE=long-and-random-alphanumeric-string
    - GITLAB_SECRETS_SECRET_KEY_BASE=long-and-random-alphanumeric-string
    - GITLAB_SECRETS_OTP_KEY_BASE=long-and-random-alphanumeric-string

    - GITLAB_ROOT_PASSWORD=
    - GITLAB_ROOT_EMAIL=

    - GITLAB_NOTIFY_ON_BROKEN_BUILDS=true
    - GITLAB_NOTIFY_PUSHER=false

    - GITLAB_EMAIL=notifications@example.com
    - GITLAB_EMAIL_REPLY_TO=noreply@example.com
    - GITLAB_INCOMING_EMAIL_ADDRESS=reply@example.com

    - GITLAB_BACKUP_SCHEDULE=daily
    - GITLAB_BACKUP_TIME=01:00

    - SMTP_ENABLED=false
    - SMTP_DOMAIN=www.example.com
    - SMTP_HOST=smtp.gmail.com
    - SMTP_PORT=587
    - SMTP_USER=mailer@example.com
    - SMTP_PASS=password
    - SMTP_STARTTLS=true
    - SMTP_AUTHENTICATION=login

    - IMAP_ENABLED=false
    - IMAP_HOST=imap.gmail.com
    - IMAP_PORT=993
    - IMAP_USER=mailer@example.com
    - IMAP_PASS=password
    - IMAP_SSL=true
    - IMAP_STARTTLS=false

    - OAUTH_ENABLED=false
    - OAUTH_AUTO_SIGN_IN_WITH_PROVIDER=
    - OAUTH_ALLOW_SSO=
    - OAUTH_BLOCK_AUTO_CREATED_USERS=true
    - OAUTH_AUTO_LINK_LDAP_USER=false
    - OAUTH_AUTO_LINK_SAML_USER=false
    - OAUTH_EXTERNAL_PROVIDERS=

    - OAUTH_CAS3_LABEL=cas3
    - OAUTH_CAS3_SERVER=
    - OAUTH_CAS3_DISABLE_SSL_VERIFICATION=false
    - OAUTH_CAS3_LOGIN_URL=/cas/login
    - OAUTH_CAS3_VALIDATE_URL=/cas/p3/serviceValidate
    - OAUTH_CAS3_LOGOUT_URL=/cas/logout

    - OAUTH_GOOGLE_API_KEY=
    - OAUTH_GOOGLE_APP_SECRET=
    - OAUTH_GOOGLE_RESTRICT_DOMAIN=

    - OAUTH_FACEBOOK_API_KEY=
    - OAUTH_FACEBOOK_APP_SECRET=

    - OAUTH_TWITTER_API_KEY=
    - OAUTH_TWITTER_APP_SECRET=

    - OAUTH_GITHUB_API_KEY=
    - OAUTH_GITHUB_APP_SECRET=
    - OAUTH_GITHUB_URL=
    - OAUTH_GITHUB_VERIFY_SSL=

    - OAUTH_GITLAB_API_KEY=
    - OAUTH_GITLAB_APP_SECRET=

    - OAUTH_BITBUCKET_API_KEY=
    - OAUTH_BITBUCKET_APP_SECRET=
    - OAUTH_BITBUCKET_URL=

    - OAUTH_SAML_ASSERTION_CONSUMER_SERVICE_URL=
    - OAUTH_SAML_IDP_CERT_FINGERPRINT=
    - OAUTH_SAML_IDP_SSO_TARGET_URL=
    - OAUTH_SAML_ISSUER=
    - OAUTH_SAML_LABEL="Our SAML Provider"
    - OAUTH_SAML_NAME_IDENTIFIER_FORMAT=urn:oasis:names:tc:SAML:2.0:nameid-format:transient
    - OAUTH_SAML_GROUPS_ATTRIBUTE=
    - OAUTH_SAML_EXTERNAL_GROUPS=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_EMAIL=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_NAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_USERNAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_FIRST_NAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_LAST_NAME=

    - OAUTH_CROWD_SERVER_URL=
    - OAUTH_CROWD_APP_NAME=
    - OAUTH_CROWD_APP_PASSWORD=

    - OAUTH_AUTH0_CLIENT_ID=
    - OAUTH_AUTH0_CLIENT_SECRET=
    - OAUTH_AUTH0_DOMAIN=
    - OAUTH_AUTH0_SCOPE=

    - OAUTH_AZURE_API_KEY=
    - OAUTH_AZURE_API_SECRET=
    - OAUTH_AZURE_TENANT_ID=

volumes:
  redis-data:
  postgresql-data:
  gitlab-data:
```



修改

```yaml
version: '2.3'

services:
  redis:
    restart: always
    image: redis:5.0.9
    command:
    - --loglevel warning
    volumes:
    - redis-data:/var/lib/redis:Z

  postgresql:
    restart: always
    image: sameersbn/postgresql:12-20200524
    volumes:
    - postgresql-data:/var/lib/postgresql:Z
    environment:
    - DB_USER=gitlab
    - DB_PASS=password
    - DB_NAME=gitlabhq_production
    - DB_EXTENSION=pg_trgm,btree_gist

  gitlab:
    restart: always
    image: sameersbn/gitlab:13.9.4
    depends_on:
    - redis
    - postgresql
    ports:
    - "10080:80" # 端口的映射
    - "10022:22" # ssh端口的映射
    volumes:
    - gitlab-data:/home/git/data:Z
    healthcheck:
      test: ["CMD", "/usr/local/sbin/healthcheck"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 5m
    environment:
    - DEBUG=false

    - DB_ADAPTER=postgresql
    - DB_HOST=postgresql
    - DB_PORT=5432
    - DB_USER=gitlab
    - DB_PASS=password
    - DB_NAME=gitlabhq_production

    - REDIS_HOST=redis
    - REDIS_PORT=6379

    - TZ=Asia/Kolkata
    - GITLAB_TIMEZONE=Kolkata

    - GITLAB_HTTPS=false # 如果这里设置成为true
    - SSL_SELF_SIGNED=false # 如果这里设置成为true，那么就是使用自签名的方式，需要gitlab配置证书

    - GITLAB_HOST=116.62.24.181 # 服务器的ip，或者改成云服务器的域名，需要配置域名解析
    - GITLAB_PORT=10080
    - GITLAB_SSH_PORT=10022
    - GITLAB_RELATIVE_URL_ROOT=
    # 这三个是默认的配置
    - GITLAB_SECRETS_DB_KEY_BASE=long-and-random-alphanumeric-string
    - GITLAB_SECRETS_SECRET_KEY_BASE=long-and-random-alphanumeric-string
    - GITLAB_SECRETS_OTP_KEY_BASE=long-and-random-alphanumeric-string

    - GITLAB_ROOT_PASSWORD=12345678 # 管理员的密码，必须是8位的
    - GITLAB_ROOT_EMAIL=aboutcroon@gmail.com # 管理员的邮箱

    - GITLAB_NOTIFY_ON_BROKEN_BUILDS=true
    - GITLAB_NOTIFY_PUSHER=false

    - GITLAB_EMAIL=notifications@example.com
    - GITLAB_EMAIL_REPLY_TO=noreply@example.com
    - GITLAB_INCOMING_EMAIL_ADDRESS=reply@example.com

    - GITLAB_BACKUP_SCHEDULE=daily
    - GITLAB_BACKUP_TIME=01:00

    - SMTP_ENABLED=false
    - SMTP_DOMAIN=www.example.com
    - SMTP_HOST=smtp.gmail.com
    - SMTP_PORT=587
    - SMTP_USER=mailer@example.com
    - SMTP_PASS=password
    - SMTP_STARTTLS=true
    - SMTP_AUTHENTICATION=login

    - IMAP_ENABLED=false
    - IMAP_HOST=imap.gmail.com
    - IMAP_PORT=993
    - IMAP_USER=mailer@example.com
    - IMAP_PASS=password
    - IMAP_SSL=true
    - IMAP_STARTTLS=false

    - OAUTH_ENABLED=false
    - OAUTH_AUTO_SIGN_IN_WITH_PROVIDER=
    - OAUTH_ALLOW_SSO=
    - OAUTH_BLOCK_AUTO_CREATED_USERS=true
    - OAUTH_AUTO_LINK_LDAP_USER=false
    - OAUTH_AUTO_LINK_SAML_USER=false
    - OAUTH_EXTERNAL_PROVIDERS=

    - OAUTH_CAS3_LABEL=cas3
    - OAUTH_CAS3_SERVER=
    - OAUTH_CAS3_DISABLE_SSL_VERIFICATION=false
    - OAUTH_CAS3_LOGIN_URL=/cas/login
    - OAUTH_CAS3_VALIDATE_URL=/cas/p3/serviceValidate
    - OAUTH_CAS3_LOGOUT_URL=/cas/logout

    - OAUTH_GOOGLE_API_KEY=
    - OAUTH_GOOGLE_APP_SECRET=
    - OAUTH_GOOGLE_RESTRICT_DOMAIN=

    - OAUTH_FACEBOOK_API_KEY=
    - OAUTH_FACEBOOK_APP_SECRET=

    - OAUTH_TWITTER_API_KEY=
    - OAUTH_TWITTER_APP_SECRET=

    - OAUTH_GITHUB_API_KEY=
    - OAUTH_GITHUB_APP_SECRET=
    - OAUTH_GITHUB_URL=
    - OAUTH_GITHUB_VERIFY_SSL=

    - OAUTH_GITLAB_API_KEY=
    - OAUTH_GITLAB_APP_SECRET=

    - OAUTH_BITBUCKET_API_KEY=
    - OAUTH_BITBUCKET_APP_SECRET=
    - OAUTH_BITBUCKET_URL=

    - OAUTH_SAML_ASSERTION_CONSUMER_SERVICE_URL=
    - OAUTH_SAML_IDP_CERT_FINGERPRINT=
    - OAUTH_SAML_IDP_SSO_TARGET_URL=
    - OAUTH_SAML_ISSUER=
    - OAUTH_SAML_LABEL="Our SAML Provider"
    - OAUTH_SAML_NAME_IDENTIFIER_FORMAT=urn:oasis:names:tc:SAML:2.0:nameid-format:transient
    - OAUTH_SAML_GROUPS_ATTRIBUTE=
    - OAUTH_SAML_EXTERNAL_GROUPS=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_EMAIL=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_NAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_USERNAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_FIRST_NAME=
    - OAUTH_SAML_ATTRIBUTE_STATEMENTS_LAST_NAME=

    - OAUTH_CROWD_SERVER_URL=
    - OAUTH_CROWD_APP_NAME=
    - OAUTH_CROWD_APP_PASSWORD=

    - OAUTH_AUTH0_CLIENT_ID=
    - OAUTH_AUTH0_CLIENT_SECRET=
    - OAUTH_AUTH0_DOMAIN=
    - OAUTH_AUTH0_SCOPE=

    - OAUTH_AZURE_API_KEY=
    - OAUTH_AZURE_API_SECRET=
    - OAUTH_AZURE_TENANT_ID=

volumes:
  redis-data:
  postgresql-data:
  gitlab-data:
```

修改好了这个 docker-compose.yml 文件后，就可以在同目录下执行 `docker-compose up -d`

## 创建备份

网址：https://github.com/sameersbn/docker-gitlab#creating-backups



```yaml
docker run --name gitlab -it --rm [OPTIONS] \
    sameersbn/gitlab:13.9.4 app:rake gitlab:backup:create
```



github 上的这个文件已经设置了一个定时任务，备份的周期是按天来备份，上述 docker-compose.yml 文件中的以下部分则是

```yaml
    - GITLAB_BACKUP_SCHEDULE=daily // 备份的周期
    - GITLAB_BACKUP_TIME=01:00 // 每天的凌晨一点钟开始备份
```

还可以设置 `GITLAB_BACKUP_EXPIRY`，也就是设置超时

| `GITLAB_BACKUP_EXPIRY` | Configure how long (in seconds) to keep backups before they are deleted. By default when automated backups are disabled backups are kept forever (0 seconds), else the backups expire in 7 days (604800 seconds). |
| ---------------------- | ------------------------------------------------------------ |
|                        |                                                              |

我们可以添加

```yaml
    - GITLAB_BACKUP_SCHEDULE=daily // 备份的周期
    - GITLAB_BACKUP_TIME=01:00 // 每天的凌晨一点钟开始备份
    - GITLAB_BACKUP_EXPIRY=604800 // 以秒为单位，这也就是7天的备份，到了第8天就会删除第1天的备份内容，总的就是保存最近7天的备份内容
```



修改完成后，然后再次 `docker-compose up -d` 去更新这个文件

紧接着，就要去运行备份的命令

如果是 docker，则是

```
docker run --name gitlab -it --rm [OPTIONS] \
    sameersbn/gitlab:13.9.4 app:rake gitlab:backup:create
```

如果是 docker-compose，则是

```
docker-compose run --rm gitlab app:rake gitlab:backup:create
```

需要在 docker-compose.yml 这个文件所在的目录下去运行这条命令，运行完则备份创建成功



## 恢复备份

网址：https://github.com/sameersbn/docker-gitlab#restoring-backups

执行如下两条命令

```yaml
docker-compose run --rm gitlab app:rake gitlab:backup:restore # List available backups 列出所有可恢复的备份
docker-compose run --rm gitlab app:rake gitlab:backup:restore BACKUP=1515629493_2020_12_06_13.9.4 # Choose to restore from 1515629493
```

第一条是列出所有可恢复的备份，然后输入一个对应的号码去备份

第二条是可以直接去备份这个号码对应的某一条（.tar结尾）



> docker-compose 的命令需要在配置文件目录下(docker-compose.yml文件目录下)执行



## Gitlab权限控制

防止错误的推送，覆盖了代码



#### 以组为单位，设置管理员

管理员来设置主干的分支，并设置哪些成员可以添加进来



角色：

- 仓库所有者，设置哪些人是管理员，可以管理哪些权限
- 开发人员
- 项目负责人，产品（只是 guest，只读权限）

### merge request

写好 git commit，来让管理员知道你这次提交和修改了哪些代码

### 及时回收权限，或者设置过期时间

有成员离开时，则需要回收权限



## gitignore 文件

- 使用GitHub 上的方便的 gitignore 文件的仓库

https://github.com/github/gitignore



当我们上一次保存了 A 文件，但这次我们把它添加到 ignore 中，则会报错，这时候我们需要清除快照

```
git rm --cached -r .
```

这时候就可以 ignore 掉 A 文件了



- 使用 vscode 插件

.gitignore generator





<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-03 下午5.26.00.png" alt="截屏2021-04-03 下午5.26.00" style="zoom:50%;" />





# 数据库

关系型数据库：

mysql, oracle, sql server, access, DB2, postgreSQL



非关系型数据库：

MongoDB, Redis, Memcached, Hbase



NoSQL 数据库的意义：

- 易扩展，高性能，高可用
- 较容易映射复杂数据（key-value）
- 无事务性要求（ACID特性）（用于秒杀，购物时）



NoSQL 设计：

- 常见场景及设计方法（内嵌，父/子引用，反范式）
- 双向关联的场景及设计原则



内嵌设计：将一个用户的所有描述属性以键值对存放在一张表里面

- 减少了关联查询
- 适用于单类需要描述的属性
- 不经常变化的属性（扩展，嵌套关联）

内嵌可以减少查询，提高查询效率

但当内嵌的内容非常庞大时，我们就要使用父引用了



父引用：存在一对多的情况中，放在同一个文档中，以数组形式存放

子引用：存在一对非常多的情况，由于数据库文档存放限制，这个时候进行反向引用

这样就使得非关系型数据库也可以像关系型数据库这样去设计了



## mongoDB

### 连接

下载 robo 3T 作为可视化工具

像之前的流程一样，在阿里云服务器上打开相关的端口

然后拉取 mongo 镜像，使用 robo 3T 连接即可



在数据库左侧，Add collections，然后再右键点击相应的 result 区域来 insert document

### 备份和恢复

一句命令备份：

首先执行

```yaml
docker exec -it <容器名称> <指令>
```

例如，我先添加了一个 admin 的用户

```
docker exec -it prem-mongo mongodump -h localhost -u admin -p 123456 -o /tmp/test
```

-h 是相应的 ip，-u 是对应的用户，-p 是密码，-o 指定备份的目录，后面还可以接 -d 来指定备份那一个数据库，如果不加 -d 就是备份所有数据库

> 必须先在数据库中添加用户，才能使用上述命令！



一句命令恢复：

```yaml
docker exec -it prem-mongo mongorestore -h localhost -u admin -p 123456 --dir /tmp/test
```



因为 /tmp/test 命令是在宿主机上，那么怎么将其挂载到镜像上去呢？

可以使用 volumn 参数将其挂载到镜像上去

也可以使用 cp 命令将宿主机上的目录拷贝到镜像上面去



## Mongoose

nodejs 里面的一个非常重要的库，用来操作 mongoDB

<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-05 下午12.26.00.png" alt="截屏2021-04-05 下午12.26.00" style="zoom:50%;" />

这张图是 mysql 里面的概念与 mongoDB 中的概念相对应的部分

例子：

```js
const mongoose = require('mongoose')

// 开头需要加上 mongodb，然后 admin:123456 是用于有 Authentication 的 mongo 输入用户名及密码的，若没有 Authentication，则直接可以写成mongodb://116.62.24.181:10050/admin，然后接 ip 和 port，最后接数据库名称
// 为了避免当前的URL字符串解析器被弃用的报错 在选项里面添加 { useNewUrlParser: true }
mongoose.connect('mongodb://admin:123456@116.62.24.181:10050/admin', { useNewUrlParser: true })

// 连接名为 users 的 collection，后面的参数就是其 schema（骨架，结构）
const User = mongoose.model('users', { name: String, age: Number, email: String })

// 存储一条数据放到上面的 collection
const instance = new User({
  name: 'croon',
  age: 23,
  email: 'aboutcroon@gmail.com'
})
instance.save().then(() => { console.log('save ok!') })
```

> mongoose 方法返回的是一个 promsie



上面是单条数据

但我们不可能每次存储修改一条数据就去连接一次数据库

所以需要一个公共的文件



连接 mongo 的文件 /config/DBHelper

```js
import mongoose from 'mongoose'
import config from './index'

// 创建连接
mongoose.connect(config.DB_URL, {
  useNewUrlParser: true,
  useUnifiedTopology: true
})

// 监听连接成功的事件
mongoose.connection.on('connected', () => {
  console.log('Mongoose connection open to ' + config.DB_URL);
})

// 监听连接异常的事件
mongoose.connection.on('error', (err) => {
  console.log('Mongoose connection error: ' + err);
})

// 断开连接
mongoose.connection.on('disconnected', () => {
  console.log('Mongoose connection disconnected')
})

export default mongoose
```



一个 model 实例文件 model/test.js

```js
import mongoose from '../config/DBHelpler'

const Schema = mongoose.Schema

const TestSchema = new Schema({
  'name': { type: String },
  'age': { type: Number },
  'email': { type: String }
})

const TestModel = mongoose.model('users', TestSchema)

export default TestModel
```



增删改查文件 model/demo.js

```js
import User from './test'

const user = {
  name: 'brian',
  age: 30,
  email: 'brian@toimc.com'
}

// 增
const insertMethods = async () => {
  const data = new User(user)
  const result = await data.save()
  console.log(result)
}

// 查
const findMethods = async () => {
  const result = await User.find()
  console.log(result)
}

// 改
const updateMethods = async () => {
  const result = await User.updateOne({ name: 'brian' }, {
    email: 'imooc@imooc.com'
  })
  console.log(result)
}

// 删
const deleteMethods = async () => {
  const result = await User.deleteOne({ name: 'brian' })
  console.log(result)
}

// deleteMethods()
insertMethods()
```



## Redis



<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-05 下午3.34.28.png" alt="截屏2021-04-05 下午3.34.28" style="zoom:50%;" />

Redis 是一个高性能的 key-value 数据库

Redis 与其他 key-value 缓存产品相比：支持数据的持久化，多数据结构 list set zset hash 等的存储，支持数据备份



Redis 特点：

- 高性能，可持久化：断电之后，缓存的数据并不是就消失了，而是存储到了宿主机上
- key-value 结构，支持多种数据类型
- 支持事务，并且数据具有原子性（要么不做，要么全做）



Redis 应用场景：

- 缓存（读写性能优异）：提升网站的访问速度，降低数据库的压力
- 计数&消息系统（高并发，例如电商网站的浏览量，视频网站的播放数据，为了保证数据的时效性，它并不会实时的将数据写到数据库中，使用 inrc 实现计数器功能，主要是在内存中进行操作）（发布/订阅阻塞队列功能，redis 实现了一个消息队列功能）
- 分布式会话 session & 分布式锁（我们通常把 session 保存在网站的服务器上，那么当一台服务器不能完全保存用户的 session 时，加入多台服务器，它们是一个 redis 集群，在其中实现 session 的一个同步）（分布式锁，例如秒杀，在这种高并发的场景下，服务器的数据库的响应不是那么的好，那么这时 redis 在内存中的响应就很快，可以充分利用其原子性，达到高性能的并发操作）



Redis vs Mongo

- 存储方式不一样：key-value vs Document
- 使用方式&可靠性不一样：MongoDB 是使用 SQL 语句去查询，并且有完整的事务的 ACID 的支持
- 应用场景不一样：Redis是高性能缓存，mongo 是借助其丰富的查询语句，可以做到海量的数据分析



下载安装：

前往 redis 官网，download 中选择 docker hub

前往 docker hub 找到 redis 镜像

https://hub.docker.com/_/redis/



前往 redis 的 github 上查看 redis.conf 默认配置文件

配置 redis.conf，缓存 redis 数据（生产需要）

https://github.com/redis/redis/blob/unstable/redis.conf



然后创建 docker-compose.yml 文件

```yaml
version: '3'
services: 
  prem-redis:
    image: 'redis'
    restart: 'always'
    container_name: 'prem-redis'
    ports:
      - '10051:6379'
    volumes:
      - /home/premredis:/data
    command: ["redis-server", "--requirepass", "123456"] # 设置用户名和密码，--requirepass 表示需要密码
```



这时会有两个警告，查看解决方案

https://blog.csdn.net/qq_18108159/article/details/103093881

https://www.cnblogs.com/faunjoe88/p/7158484.html



## Redis Cli

### 设置 取值

一句命令进入到 redis 的交互终端（prem-redis 是 docker 的容器名）

```
docker exec -it prem-redis redis-cli
```

或者先进入到镜像中，再进入到 redis-cli

```
docker exec -it prem-redis /bin/bash
redis-cli
```



接着输入密码（因为上面 docker-compsoe 文件中设置了 requirepass）

```
auth 123456
```



还可以使用 CONFIG SET requirepass password 来修改密码

http://doc.redisfans.com/connection/auth.html



redis 共有 16 个 databases（index 为 0 - 15），通过 `select` 命令来选择数据库

```
select 1
```

`INCR` 和 `DECR` 分别是增加 1 和减去 1

`keys *` 可以罗列所有的键值



Hset 命令，即给每一个 json 数值对一个键值

```
hset croon name liuchang
hset croon age 23
```

这里 croon 为键值，name-liuchang, age-23 分别是两个键值对



hmset 即是批量设置

```
hmset croon name liuchang age 23
```



### 发布 订阅

publish http://doc.redisfans.com/pub_sub/publish.html

subscribe http://doc.redisfans.com/pub_sub/subscribe.html



### 备份与恢复

<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-05 下午9.25.59.png" alt="截屏2021-04-05 下午9.25.59" style="zoom:50%;" />

dump.rdb 即是备份出来的文件，将其保存起来再次放到 data 目录下时即能恢复



## Redis GUI

Another redis desktop manager



## Redis 的 nodejs 库

Redis 的 nodejs 库，名字就叫 redis



```js
const REDIS = {
  host: '116.62.24.181',
  port: 10051,
  password: '123456'
}
```



```js
import redis from 'redis'
import { promisifyAll } from 'bluebird'
import config from './index'

const options = {
  host: config.REDIS.host,
  port: config.REDIS.port,
  password: config.REDIS.password,
  detect_buffers: true,
  // 官方文档中的 retry_strategy
  retry_strategy: function (options) {
    if (options.error && options.error.code === 'ECONNREFUSED') {
        // End reconnecting on a specific error and flush all commands with
        // a individual error
        return new Error('The server refused the connection');
    }
    if (options.total_retry_time > 1000 * 60 * 60) {
        // End reconnecting after a specific timeout and flush all commands
        // with a individual error
        return new Error('Retry time exhausted');
    }
    if (options.attempt > 10) {
        // End reconnecting with built in error
        return undefined;
    }
    // reconnect after
    return Math.min(options.attempt * 100, 3000);
  }
}

// const client = redis.createClient(options)
// 将其转换成异步的 promise 方法
// 这里直接使用 promisifyAll 而不用 promisify
// 原本是
// const client = redis.createClient(options)
// const getAsync = promisify(client.get).bind(client)
// getAsync.then(console.log).catch(console.error)
// 用下面这种就不用去 bind 当前的 client 了
const client = promisifyAll(redis.createClient(options))

client.on('error', (err) => {
  console.log('Redis Client Error:' + err)
})

const setValue = (key, value) => {
  if (typeof value === 'undefined' || value == null ||value === '') {
    return
  }
  if (typeof value === 'string') {
    client.set(key, value)
  } else if (typeof value === 'object') {
    // { key1: value1, key2: value2}
    // Object.keys(value) => [key1, key2]
    Object.keys(value).forEach((item) => {
      // redis.print 是用来打印返回成功的日志
      client.hset(key, item, value[item], redis.print)
    })
  }
}

// const {promisify} = require('util');
// const getAsync = promisify(client.get).bind(client);

const getValue = (key) => {
  return client.getAsync(key)
}

const getHValue = (key) => {
  // v8 Promisify method use util, must node > 8
  // return promisify(client.hgetall).bind(client)(key)

  // bluebird async
  return client.hgetallAsync(key)
}

const delValue = (key) => {
  client.del(key, (err, res) => {
    if (res === 1) {
      console.log('delete successfully');
    } else {
      console.log('delete redis key error:' + err)
    }
  })
}

export {
  client,
  setValue,
  getValue,
  getHValue,
  delValue
}
```



实际操作

```js
import { getValue, setValue, getHValue, delValue } from './RedisConfig'

setValue('imooc', 'imooc message from redis client')

getValue('imooc').then((res) => {
  console.log('getValue:' + res)
})

delValue('imooc')

setValue('imoocobj', {name: 'brian', age: 30, email: 'brian@toimc.com'})

getHValue('imoocobj').then((res) => {
  console.log('getHValue:' +JSON.stringify(res, null, 2))
})
```







# 后端

## 鉴权，加密，HTTPS

- 理解鉴权，加密，HTTPS 等核心概念
- 熟悉常见的鉴权方式（JWT，session）及优缺点
- 使用 JWT 方式开发登录鉴权模块，设计相应接口



### 鉴权

jwt：json web token（通常就是在 header 部分带上 token，它是无状态的，不用去考虑多服务器的时候 session 的同步）

Oauth鉴权是第三方登录的时候才使用



优缺点：

- session/cookie，优点：较易扩展，简单。缺点：安全性低，性能低，服务端存储，多服务器同步 session 困难，跨平台困难
- JWT：优点：易扩展，支持移动设备，跨应用调用，安全，承载信息丰富（json类型的数据）。缺点：刷新与过期处理，payload 不易过大，中间人攻击
- Oauth：优点：开放（任何服务器和软件商都可以去使用），安全（没有使用到密钥信息），简单，权限指定。缺点：需要增加授权服务器，增加网络请求

### 算法/加密

对数据进行加密，将明文按照某种算法进行处理，使其变得不可读

Base64

MD5-SHA-1

DES/AES

RSA/ECC

### HTTPS

HTTP 协议加上 SSL 证书组成，HTTPS 对数据传输进行了加密，可以很好的防范中间人，防止传输密文信息的时候被别人截取

对通信信道进行加密



## JWT

一个 jwt 由三部分构成：Header，payload，signature

header：token 加密的方式， token 的类型

payload：token 中包含的用户的信息

signature：header 的 base64 的值 + payload 的 base64 的值 + signature 生成的字符串

主要是去比对 signature 签名是否一致



jwt 特点：

- 防 CSRF（主要是伪造请求，带上 cookie），因为 jwt 在 header 带上 token，所以没有了 cookie，所以就没有伪造请求的影响了
- 适合移动端应用（因为移动端对 cookie 的支持不怎么好）
- 无状态，不需要像 session 一样在服务器侧去存储会话的状态。还可以对传输数据进行编码，保证其安全性



在线的 jwt 网站：jwt.io





<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-03 下午7.52.40.png" alt="截屏2021-04-03 下午7.52.40" style="zoom:50%;" />

服务端收到每次请求的 token 后，用 secret 解密 signature 看账号密码是否符合，验证通过则返回数据

jwt 不会记录 token 是哪个用户的，也不会记录 token 的状态

所以中间人如果拿到了 token 的话也可以发起攻击，不是绝对的安全

这时可以对通信信道进行加密，让中间人无法劫持请求，即使截取了，但他没有 ssl 证书，所以获取不到加密的数据的



API 安全设计：

通信信道加密：使用 HTTPS

通信数据加密：密文 + 加密关键数据

通信安全策略：授权中间（oauth），尝试次数（超过多少次就停止访问），过期策略，短信验证码...





# 登录注册





<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-03 下午8.40.14.png" alt="截屏2021-04-03 下午8.40.14" style="zoom:50%;" />







<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-03 下午8.40.32.png" alt="截屏2021-04-03 下午8.40.32" style="zoom:50%;" />

## vee-validate



## axios 的封装

request.config.withCredentials 表示是否在跨域请求中将凭证带上。若设为 true，则会在每次跨域请求中都带上我们的凭证，通常是 cookie



## 登录

验证码部分：有一个标识符和图片验证码进行唯一的对应，每当客户端请求服务端的验证码时，会将这个标识符带上发送给服务端，这个标识符得是唯一的，且可以大批量的产生

这样服务到就可以通过这个标识符去查看 redis 缓存中的 key，获取到对应的 value，value 记录了验证码的数据及过期时间，从而来验证这个验证码



> 也可以将验证码与 session id 进行绑定 



这个标识符可以使用随机数，也可以使用 uuid 工具



server 下，getCapcha 请求

```js
import svgCaptcha from 'svg-captcha'
import { getValue, setValue, getHValue, delValue } from '../config/RedisConfig'

class PublicController {
  constructor() {}
  async getCaptcha(ctx) {
    const body = ctx.request.query
    // body.sid 即是请求发送过来的 sid
    // console.log(body.sid)
    const newCaptca = svgCaptcha.create({
      size: 4,
      ignoreChars: '0o1il',
      color: true,
      noise: Math.floor(Math.random() * 5),
      width: 150,
      height: 38,
    })
    // newCaptca.text 即是验证码的文字内容，newCaptca.data 即是验证码 svg
    console.log(newCaptca)
    // 在 redis 中 set
    setValue(body.sid, newCaptca.text)
    getValue(body.sid).then(res => {
      console.log(res)
    })
    ctx.body = {
      code: 200,
      data: newCaptca.data,
    }
  }
}

export default new PublicController()
```



使用 redis 设置其过期时间

在 noderedis 的 github 上搜索 expire

<img src="/Users/croon/Library/Application Support/typora-user-images/截屏2021-04-05 下午10.48.59.png" alt="截屏2021-04-05 下午10.48.59" style="zoom:50%;" />

多传两个参数即可设置过期时间



token 其实不论存放在哪里都是比较安全的

因为即使有人中途截取了 token，但他只知道 payload，不知道服务端的 secret 校验的算法

所以 token 是一个非常安全的鉴权机制了

想要进一步的安全的话，可以采用 `动态的 secret`，并设置较短的 token 过期时间，然后同时设置客户端刷新 token



### jwt

进行完 vee-validate 的校验后，开始给后端集成 jwt

我们需要安装 `koa-jwt` 和 `jsonwebtoken`



> 当我们安装了 `koa-jwt` 时，koa web 框架只是拥有了鉴权的功能，但是 jwt 怎样去产生和怎样去校验都是要通过 `jsonwebtoken`
>
> jsonwebtoken.sign() 是产生 token，jsonwebtoken.verify() 是将 token 中的字段解析出来
>
> 而 koa-jwt({ secret: xxx }) 才是鉴权，也就是鉴定该用户发送的请求中的 token 是否正确
>
> 在服务端可以先鉴权，然后再去将其解析出来



#### jsonwebtoken

```js
const jwt = require('jsonwebtoken')

// 产生 token，返回给前端
jwt.sign(payload, secretOrPublicKey, [options, callback])

// 接收前端传递过来的 token，进行解析，解析完后的 tokenData 是一个对象，包含了上面 payload 中的信息
const tokenData = jwt.verify(token, secretOrPublicKey, [options, callback])
```

> koa-jwt 的 package.json 中下载了 jsonwebtoken，所以我们直接下载 koa-jwt，就可以这两个都使用了



`sign()` 方法的第一个参数 payload 是明文的，所以不能放置敏感的数据，可以放一些用户 id，过期时间之类的

过期时间可以设置在 options 中，也可以直接设置在 payload 中，但不能同时在两个地方都设置

https://github.com/auth0/node-jsonwebtoken#jwtsignpayload-secretorprivatekey-options-callback

> There are no default values for `expiresIn`, `notBefore`, `audience`, `subject`, `issuer`. These claims can also be provided in the payload directly with `exp`, `nbf`, `aud`, `sub` and `iss` respectively, but you ***can't\*** include in both places.

```js
const token = jwt.sign({
  data: tokenData,
  exp: Math.floor(Date.now() / 1000) + (60 * 60 * 24 * 14)
}, config.jwtSecret)
```



#### koa-jwt

koa-jwt 是如何对请求中的 token 进行鉴权的呢

> The resolution order for the token is the following. The first non-empty token resolved will be the one that is verified.
>
> - `opts.getToken` function.
> - check the cookies (if `opts.cookie` is set).
> - check the Authorization header for a bearer token.

分别是从请求中的这三个字段中去找



若存放在了 cookie 中：

```json
cookies:token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjp7Im5hbWUiOiLnrqHnkIblkZgiLCJ1c2VybmFtZSI6ImFkbWluIiwiZW1haWwiOiIiLCJzdGF0dXMiOjEsInBhc3N3b3JkVXBkYXRlUmVjb3JkcyI6W3sicGFzc3dvcmQiOiJhYmMuMTIzNDU2IiwidGltZSI6IjIwMjEtMDQtMDdUMDM6MjM6MTIuNjY2WiJ9LHsicGFzc3dvcmQiOiJhYmMuMTIzNDUiLCJ0aW1lIjoiMjAyMS0wNC0wN1QwMzoyMjoxMy41OTNaIn0seyJwYXNzd29yZCI6ImFiYy4xMjM0NTY3IiwidGltZSI6IjIwMjEtMDQtMDdUMDM6MjE6NDYuNzk2WiJ9LHsicGFzc3dvcmQiOiJhYmMuMTIzNDU2IiwidGltZSI6IjIwMjEtMDQtMDdUMDM6MjE6MjMuODEyWiJ9LHsicGFzc3dvcmQiOiJhYmMuMTIzNDUiLCJ0aW1lIjoiMjAyMS0wNC0wN1QwMzoxODo0MC43OTVaIn0seyJwYXNzd29yZCI6IjEyMzQ1NiIsInRpbWUiOiIyMDIxLTA0LTAxVDA0OjEyOjAyLjYyNFoifV0sImNyZWF0ZVRpbWUiOiIyMDIxLTA0LTAxVDA0OjEyOjAyLjYyNFoiLCJ1cGRhdGVUaW1lIjoiMjAyMS0wNC0wN1QwMzoyMzoxMi42NjZaIiwiaWQiOiI2MDY1NDgxMmJiZGFjZTAwNTQwN2U1ZDMifSwiZXhwIjoxNjE5MDgyMDE2LCJpYXQiOjE2MTc4NzI0MTZ9.YWOPDJgAJRNpz4AaIBYynESX1mPcz462l689qn2WQ_0; io=gMg8lJPQSiH4cVgZAAVO
```

若存放在了 Authorization header 中：

```json
Authorization: Bearer <token字段>

// 例如
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImNyb29uIiwiZXhwIjoxNjE5MTQ2NjQ2LCJpYXQiOjE2MTc5MzcwNDZ9.XeQC17iBCEtD9GCNjLJ6hgF5yqQ5XrWYujpdcmWvwdE
```



可以在 postman 中测试

比如某接口，添加一个请求参数（Bearer + 一个空格 + token）

```json
Authorization: Bearer <token字段>
```

如果 token 符合，则校验通过，不符合则返回错误信息



koa-jwt 的使用：

```js
// app.js

// unless 表示不需要 token 权限也能访问的网址
const jwt = JWT({ secret: config.jwtSecret }).unless({ path: [/^\/api\/login/, /^\/api\/forget/] })

/**
 * 使用koa-compose 集成中间件
 */
const middleware = compose([
  koaBody(),
  statics(path.join(__dirname, '../public')),
  cors(),
  jsonutil({ pretty: false, param: 'pretty' }),
  helmet(),
  jwt
])
```



处理鉴权不通过的的请求：

koa-jwt 上有处理错误的例子

但这里还是使用统一的错误捕获文件 `response.js`，也可以捕获 koa-jwt 的错误

> 记住 koa-jwt 要通过 app.use() 来使用，不能通过 JWT({ secret: ... }).unless()() 的函数形式调用，通过函数形式调用的话会直接报错



也可以直接不使用 koa-jwt

```js
'use strict'
const jwt = require('jsonwebtoken')
const config = require('../config')

const whitelist = [
  '/api/login',
  '/api/forget',
  '/api/getCaptcha',
]

export default async (ctx, next) => {
  const { path } = ctx
  if (whitelist.includes(path)) {
    await next()
  } else {
    const token = ctx.cookies.get('token')
    if (typeof token === 'string') {
      // const jwtData = jwt.verify(token, config.jwtSecret)
      // if (jwtData.exp * 1000 < new Date().getTime()) {
      //   throw { status: 401, message: '未登录' }
      // }
      // // token中获取到本次token包含checkPasswordUpdate， 说明密码已经过期需要重置密码，只有重置密码的接口可以通过
      // if (jwtData.checkPasswordUpdate && path !== '/api/resetPwd') {
      //   throw { status: 401, message: '未登录' }
      // }
      // ctx.userInfo = jwtData.data
      await next()
    } else {
      throw { status: 401, message: '未登录' }
    }
  }
}

```

直接 `const token = ctx.cookies.get('token')`，如果 token 错误或者不存在的话就直接 throw 401



#### token

token 的使用：

在客户端发每次请求的时候带上，可以在 axios 的请求拦截器中加上，也可以直接服务端返回 `set-cookie`，然后客户端接下来的请求就都会自动在请求头的 cookie 中带上 token



如果 token 过期，服务端会检测到其过期，返回 401

客户端的 axios 封装里面拦截了错误，并且在 401 的时候直接重定向到登录页面



### 登录逻辑

- 接收用户的数据
- 验证图片验证码的时效性，正确性
- 验证用户账号密码是否正确
- 返回 token



```js
async login (ctx) {
  /**
     * 接收用户的数据
     * 验证图片验证码的时效性，正确性
     * 验证用户账号密码是否正确
     * 返回 token
     */
  // 接收用户的数据
  const { body } = ctx.request
  const sid = body.sid
  const code = body.code
  // 验证图片验证码的时效性，正确性
  const checked = await checkCode(sid, code)
  if (checked) {
    // 验证用户账号密码是否正确
    const username = body.username
    const password = body.password
    const user = await userService.getUser({
      username,
      password
    })
    if (user.password === password) {
      const token = jsonwebtoken.sign({
        id: 'croon',
        exp: Math.floor(Date.now() / 1000) + (60 * 60 * 24 * 14)
      }, config.jwtSecret)
      ctx.result(200, {
        token
      }, 'Login Success')
    } else {
      ctx.result(404, null, '密码不正确')
    }
  } else {
    ctx.result(401, null, '图片验证码不正确')
  }
}
```



### 错误处理

error.message 是错误的信息

error.stack 是错误产生的地方



### alias

下载 node modules resolve

并创建一个 `jsconfig.json` 文件

语法可以在官网文档查看：https://code.visualstudio.com/docs/languages/javascript#_javascript-projects-jsconfigjson

```json
{
  "compilerOptions": {
    "target": "es2017",
    "allowSyntheticDefaultImports": false,
    "baseUrl": "./",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "exclude": ["node_modules", "dist"]
}
```



### 登录中存在的问题

1. 如果 axios 里使用了 baseUrl，那么发送出去的请求将不会自动携带 cookie，不使用时才会自动携带 cookie



# 数据库设计

mango中，ObjectId 可以直接和 String 类型对应，例如发帖信息中的 uid 和用户信息中的 uid 对应



当 content 很长时，可以用文档的形式存储，但不建议直接在 content 中存储图片的内容，而是存储图片的路径更好一些



# 接口设计

